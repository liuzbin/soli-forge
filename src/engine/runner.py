import os
import traceback
import threading
from datetime import datetime
from sqlalchemy.orm import Session
from src.db.session import SessionLocal
from src.db.models import Task, StreamLog, TaskArtifact
from src.engine.tools.file_manager import FileManager
from src.engine.graph.workflow import create_graph
# ğŸ‘‡ å¼•å…¥æ—¥å¿—å·¥å…·
from src.core.logger import log_to_db

MAX_CONCURRENT_TASKS = 3
task_semaphore = threading.Semaphore(MAX_CONCURRENT_TASKS)


def update_task_phase(task_id: str, phase_name: str):
    db = SessionLocal()
    try:
        task = db.query(Task).filter(Task.id == task_id).first()
        if task:
            task.current_phase = phase_name
            db.commit()
    except Exception as e:
        print(f"Error updating phase: {e}")
    finally:
        db.close()


def archive_logs_to_file(task_id: str):
    db = SessionLocal()
    try:
        logs = db.query(StreamLog).filter(StreamLog.task_id == task_id).order_by(StreamLog.timestamp).all()
        if not logs:
            return

        full_log_content = "\n".join([f"[{log.timestamp}] [{log.level}] {log.content}" for log in logs])

        fm = FileManager(db, task_id)
        log_filename = f"execution_{task_id}.log"
        log_path = fm.task_dir / log_filename

        with open(log_path, "w", encoding="utf-8") as f:
            f.write(full_log_content)

        artifact = TaskArtifact(
            task_id=task_id,
            artifact_type="log_file",
            filename=log_filename,
            file_path=str(log_path.relative_to(fm.settings.BASE_DIR)),
            phase="archive"
        )
        db.add(artifact)
        db.commit()
        # å°†å½’æ¡£åŠ¨ä½œä¹Ÿè®°å½•åˆ°æ—¥å¿—
        log_to_db(task_id, f"âœ… Logs archived to {log_filename}")

    except Exception as e:
        print(f"âŒ Log archive failed: {e}")
    finally:
        db.close()


def run_agent_task(task_id: str):
    print(f"Task {task_id} is waiting for execution slot...")

    # è¿™ä¸€å¥åœ¨è·å–é”ä¹‹å‰ï¼Œå…ˆåˆ«å†™æ•°æ®åº“ï¼Œé˜²æ­¢é˜»å¡

    with task_semaphore:
        print(f"ğŸš€ Task {task_id} acquired slot!")
        # ğŸ‘‡ å†™å…¥æ•°æ®åº“ï¼Œå‰ç«¯å¯è§
        log_to_db(task_id, "ğŸš€ Task acquired execution slot. Initializing environment...", "INFO")

        db = SessionLocal()
        task = db.query(Task).filter(Task.id == task_id).first()

        if not task:
            print(f"Task {task_id} not found.")
            db.close()
            return

        task.status = "running"
        task.current_phase = "Initializing"
        db.commit()

        # Initialize State
        fm = FileManager(db, task_id)
        try:
            original_contract_path = fm.original_dir / task.contract_name

            # ğŸ‘‡ æ‰“å°è°ƒè¯•ä¿¡æ¯åˆ°å‰ç«¯
            log_to_db(task_id, f"ğŸ“‚ Reading contract from: {original_contract_path}", "DEBUG")

            with open(original_contract_path, "r", encoding="utf-8") as f:
                original_code = f.read()

        except Exception as e:
            error_msg = f"Could not read original file: {str(e)}"
            print(f"âŒ {error_msg}")
            traceback.print_exc()

            # ğŸ‘‡ å°†é”™è¯¯å†™å…¥æ•°æ®åº“ï¼Œè®©ç”¨æˆ·çŸ¥é“ä¸ºä»€ä¹ˆå¤±è´¥
            log_to_db(task_id, f"âŒ Critical Error: {error_msg}", "ERROR")

            task.status = "failed"
            task.result_summary = error_msg
            db.commit()
            db.close()
            return

        initial_state = {
            "task_id": task_id,
            "original_source": original_code,
            "current_source": original_code,
            "current_phase": "static_scan",
            "round_count": 0,
            "consecutive_success": 0,
            "max_retries": 5,
            "max_rounds": 5,
            "slither_report": "",
            "fuzz_logs": "",
            "exploit_code": "",
            "judge_result": "",
            "fix_history": [],
            "execution_status": "running"
        }

        app = create_graph()

        try:
            log_to_db(task_id, "ğŸ¤– AI Agents workflow started.", "INFO")

            final_state = app.invoke(initial_state)

            db.expire_all()
            task = db.query(Task).filter(Task.id == task_id).first()

            if task.status == "stopped":
                log_to_db(task_id, "ğŸ›‘ Task was stopped by user.", "WARNING")
            else:
                status = final_state.get("execution_status", "unknown")

                if status == "stopped":
                    task.status = "stopped"
                    task.result_summary = "Task stopped during execution."
                elif status == "secure" or status == "pass":
                    task.status = "completed"
                    task.result_summary = "All threats mitigated. Contract is secure."
                elif status == "needs_fix":
                    task.status = "failed"
                    task.result_summary = "Vulnerabilities persist after repair attempts."
                elif status == "fail_timeout":
                    task.status = "failed"
                    task.result_summary = "Max retries reached."
                elif status == "fail_error":
                    task.status = "failed"
                    task.result_summary = "System error during execution."
                else:
                    task.status = "completed" if status == "secure" else "failed"

                task.current_phase = "Finished"
                log_to_db(task_id, f"ğŸ Workflow finished with status: {task.status}", "INFO")

        except Exception as e:
            error_msg = f"System Error: {str(e)}"
            print(f"âŒ Runner Execution Exception: {e}")
            traceback.print_exc()

            # ğŸ‘‡ å¼‚å¸¸ä¸ŠæŠ¥åˆ°å‰ç«¯
            log_to_db(task_id, f"âŒ Workflow Crash: {error_msg}", "ERROR")

            db.expire_all()
            task = db.query(Task).filter(Task.id == task_id).first()
            if task.status != "stopped":
                task.status = "failed"
                task.result_summary = error_msg
        finally:
            archive_logs_to_file(task_id)

            from sqlalchemy import func
            now = datetime.now()

            task = db.query(Task).filter(Task.id == task_id).first()
            task.finished_at = now

            if task.started_at:
                start_time = task.started_at
                if isinstance(start_time, str):
                    try:
                        start_time = datetime.fromisoformat(str(start_time))
                    except:
                        pass

                if isinstance(start_time, datetime):
                    delta = now - start_time
                    task.duration = int(delta.total_seconds())

            db.commit()
            db.close()