import os
from sqlalchemy.orm import Session
from src.db.session import SessionLocal
from src.db.models import Task, StreamLog, TaskArtifact
from src.engine.tools.file_manager import FileManager
from src.engine.graph.workflow import create_graph
import threading


MAX_CONCURRENT_TASKS = 3
task_semaphore = threading.Semaphore(MAX_CONCURRENT_TASKS)


# === è¾…åŠ©å‡½æ•°ï¼šæ›´æ–°é˜¶æ®µ ===
def update_task_phase(task_id: str, phase_name: str):
    """ä¾› Workflow èŠ‚ç‚¹è°ƒç”¨ï¼Œå®æ—¶æ›´æ–°æ•°æ®åº“çŠ¶æ€"""
    db = SessionLocal()
    try:
        task = db.query(Task).filter(Task.id == task_id).first()
        if task:
            task.current_phase = phase_name
            db.commit()
    except Exception as e:
        print(f"Error updating phase: {e}")
    finally:
        db.close()


# === è¾…åŠ©å‡½æ•°ï¼šæ—¥å¿—å½’æ¡£ ===
def archive_logs_to_file(task_id: str):
    """ä»»åŠ¡ç»“æŸæ—¶ï¼Œå°† DB æ—¥å¿—è½¬å­˜ä¸ºæ–‡ä»¶"""
    db = SessionLocal()
    try:
        # 1. æŸ¥è¯¢æ‰€æœ‰æ—¥å¿—
        logs = db.query(StreamLog).filter(StreamLog.task_id == task_id).order_by(StreamLog.timestamp).all()
        if not logs:
            return

        # 2. æ‹¼æ¥å†…å®¹
        full_log_content = "\n".join([f"[{log.timestamp}] [{log.level}] {log.content}" for log in logs])

        # 3. å†™å…¥æ–‡ä»¶
        fm = FileManager(db, task_id)
        log_filename = f"execution_{task_id}.log"
        log_path = fm.task_dir / log_filename

        with open(log_path, "w", encoding="utf-8") as f:
            f.write(full_log_content)

        # 4. è®°å½• Artifact (ç”¨äºå†å²æŸ¥è¯¢ä¸‹è½½)
        artifact = TaskArtifact(
            task_id=task_id,
            artifact_type="log_file",
            filename=log_filename,
            file_path=str(log_path.relative_to(fm.settings.BASE_DIR)),
            phase="archive"
        )
        db.add(artifact)
        db.commit()
        print(f"âœ… Logs archived to {log_filename}")

    except Exception as e:
        print(f"âŒ Log archive failed: {e}")
    finally:
        db.close()


# === ä¸»è¿è¡Œé€»è¾‘ ===
def run_agent_task(task_id: str):
    # 1. å°è¯•è·å–æ‰§è¡Œä»¤ç‰Œ
    print(f"Task {task_id} is waiting for execution slot...")

    # è¿™è¡Œä»£ç ä¼šé˜»å¡ï¼Œç›´åˆ°æœ‰ç©ºé—²åé¢
    with task_semaphore:
        print(f"ğŸš€ Task {task_id} acquired slot! Starting execution...")
        """
        åå° Worker æ‰§è¡Œ LangGraph å·¥ä½œæµ
        """
        db = SessionLocal()
        task = db.query(Task).filter(Task.id == task_id).first()

        if not task:
            print(f"Task {task_id} not found.")
            db.close()
            return

        # Update status to running
        task.status = "running"
        task.current_phase = "Initializing"
        db.commit()

        # Initialize State
        fm = FileManager(db, task_id)
        try:
            original_contract_path = fm.original_dir / task.contract_name
            with open(original_contract_path, "r", encoding="utf-8") as f:
                original_code = f.read()
        except Exception as e:
            task.status = "failed"
            task.result_summary = f"Could not read original file: {str(e)}"
            db.commit()
            db.close()
            return

        # Initial Agent State
        initial_state = {
            "task_id": task_id,
            "original_source": original_code,
            "current_source": original_code,
            "current_phase": "static_scan",
            "round_count": 0,
            "consecutive_success": 0,
            "max_retries": 5,
            "max_rounds": 5,
            "slither_report": "",
            "fuzz_logs": "",
            "exploit_code": "",
            "judge_result": "",
            "fix_history": [],
            "execution_status": "running"
        }

        # Execute Graph
        app = create_graph()

        try:
            # Invoke the graph
            final_state = app.invoke(initial_state)

            # é‡æ–°æ‹‰å–æœ€æ–°çŠ¶æ€
            db.expire_all()
            task = db.query(Task).filter(Task.id == task_id).first()

            if task.status == "stopped":
                print(f"Task {task_id} was stopped by user (DB check).")
            else:
                status = final_state.get("execution_status", "unknown")

                if status == "stopped":
                    task.status = "stopped"
                    task.result_summary = "Task stopped during execution."

                # å…¼å®¹ workflow.py è¿”å›çš„ "secure" çŠ¶æ€
                elif status == "secure" or status == "pass":
                    task.status = "completed"
                    task.result_summary = "All threats mitigated. Contract is secure."

                # å¤„ç†æœªé€šè¿‡çš„æƒ…å†µ
                elif status == "needs_fix":
                    task.status = "failed"
                    task.result_summary = "Vulnerabilities persist after repair attempts."

                elif status == "fail_timeout":
                    task.status = "failed"
                    task.result_summary = "Max retries reached."
                elif status == "fail_error":
                    task.status = "failed"
                    task.result_summary = "System error during execution."
                else:
                    # å…œåº•
                    task.status = "completed" if status == "secure" else "failed"

                task.current_phase = "Finished"

        except Exception as e:
            print(f"Runner Exception: {e}")
            db.expire_all()
            task = db.query(Task).filter(Task.id == task_id).first()
            if task.status != "stopped":
                task.status = "failed"
                task.result_summary = f"System Error: {str(e)}"
        finally:
            # === æ ¸å¿ƒï¼šå½’æ¡£æ—¥å¿— ===
            archive_logs_to_file(task_id)

            from sqlalchemy import func
            task.finished_at = func.now()
            db.commit()
            db.close()
